{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퍼셉트론\n",
    "퍼셉트론은 엄연히 말하자면 딥러닝은 아니지만 딥러닝의 뉴런과 상당히 닮은 분류기이며, 뉴런의 계산 과정과 활성화 함수를 이해하기 위한 최적의 실습 예제이다.  \n",
    "뉴런은 활성화함수를 자유롭게 선택할 수 있는 반면, 퍼셉트론은 스텝함수라는 활성화 함수만을 사용한다.\n",
    "\n",
    "**뉴런의 출력값**: 활성화함수(가중치 * 입력값 + 편향값)  \n",
    "**퍼셉트론의 출력값**: 스텝함수(가중치 * 입력값 + 편향값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상수 설정\n",
    "코드의 이해도를 높이기 위해 1은 True, 0은 False, 편향값(bias)은 1로 지정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "F = 0.0\n",
    "bias = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AND_data():\n",
    "    X = [\n",
    "            [F, F, bias],\n",
    "            [F, T, bias],\n",
    "            [T, F, bias],\n",
    "            [T, T, bias]\n",
    "        ]\n",
    "    y = [ [F],[F],[F],[T]]\n",
    "    return X, y\n",
    "\n",
    "def get_OR_data():\n",
    "    X = [\n",
    "            [F, F, bias],\n",
    "            [F, T, bias],\n",
    "            [T, F, bias],\n",
    "            [T, T, bias]\n",
    "        ]\n",
    "    y = [ [F], [T], [T], [T]]\n",
    "    return X, y\n",
    "\n",
    "def get_XOR_data():\n",
    "    X = [\n",
    "        [F, F, bias],\n",
    "        [F, T, bias],\n",
    "        [T, F, bias],\n",
    "        [T, T, bias]\n",
    "    ]\n",
    "    y = [ [F], [T], [T], [F]]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실습할 연산을 선택합니다.\n",
    "X, y = get_AND_data()\n",
    "# X, Y = get_OR_data()\n",
    "# X, Y = get_XOR_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성\n",
    "## 퍼셉트론 구현하기\n",
    "\n",
    "논리 연상용 퍼셉트론을 구현해보자.  \n",
    "논리 연산을 위한 입력값 X, Y와 편향값(b)을 받을 것이므로 weight를 [3,1]로 설정한다.  \n",
    "3은 세개의 입력을 의미하고 1은 한 개의 뉴런임을 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self):\n",
    "        # 논리 연산을 위한 X, Y와 편향값(b)를 받을 것이므로, weight를 [3,1]로 설정한다\n",
    "        # 3은 세개의 입력을 의미하고, 1는 한개의 뉴런임을 의미한다\n",
    "        self.W = tf.Variable(tf.random.normal([3,1]))\n",
    "        \n",
    "    def train(self,X):\n",
    "        err = 1\n",
    "        epoch, max_epochs = 0,20\n",
    "        while err > 0.0 and epoch < max_epochs:\n",
    "            epoch += 1\n",
    "            self.optimize(X)\n",
    "            # MSE (평균제곱오차)를 관찰하며, 학습이 진행되는 동안 에러(MSE)가 줄어듬을 확인함\n",
    "            err = self.mse(y, self.pred(X)).numpy()\n",
    "            print('epoch:', epoch, 'mse:', err)\n",
    "            \n",
    "\n",
    "    @tf.function\n",
    "    def faster_pred(self, X):\n",
    "        return self.step(tf.matmul(X, self.W))\n",
    "    \n",
    "    def pred(self, X):\n",
    "        return self.step(tf.matmul(X, self.W))\n",
    "    \n",
    "    def mse(self, y, y_hat):\n",
    "        return tf.reduce_mean(tf.square(tf.subtract(y, y_hat)))\n",
    "    \n",
    "    # 퍼셉트론은 스텝 함수를 활성화함수로 사용한다. step(x) = {1 if x > 0; 0 otherwise}\n",
    "    def step(self, x):\n",
    "        #step(x) = {1 if x >0; 0 otherwise}\n",
    "        return tf.dtypes.cast(tf.math.greater(x,0), tf.float32)\n",
    "    \n",
    "    def optimize(self, X):\n",
    "        '''\n",
    "        퍼셉트론은 경사하강법을 이용한 최적화가 불가능하다.\n",
    "        매번 학습을 진행할 때마다 가중치를 아래의 룰에 맞게 업데이트한다.\n",
    "        \n",
    "        if target == 1 and activation == 0:\n",
    "            w_new = w_old + input\n",
    "        \n",
    "        if target == 0 and activation == 1:\n",
    "            w_new = w_old - input\n",
    "        \n",
    "        위의 두가지 조건은 아래의 코드로 간단히 구현 가능하다.\n",
    "        '''\n",
    "        delta = tf.matmul(X, tf.subtract(y, self.step(tf.matmul(X, self.W))), transpose_a=True)\n",
    "        self.W.assign(self.W+delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 mse: 0.25\n",
      "epoch: 2 mse: 0.25\n",
      "epoch: 3 mse: 0.25\n",
      "epoch: 4 mse: 0.5\n",
      "epoch: 5 mse: 0.25\n",
      "epoch: 6 mse: 0.0\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron()\n",
    "perceptron.train(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(perceptron.pred(X).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.function 속도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.8 µs ± 5.43 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit perceptron.pred(X).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137 µs ± 5.95 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit perceptron.faster_pred(X).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_timeit = timeit.timeit(lambda: perceptron.pred(X).numpy(), number=100)\n",
    "faster_pred_timeit = timeit.timeit(lambda: perceptron.faster_pred(X).numpy(), number=100)\n",
    "time_diff = round(pred_timeit / faster_pred_timeit, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faster_pred(@tf.function) is 0.6 times faster than pred!\n"
     ]
    }
   ],
   "source": [
    "print(\"faster_pred(@tf.function) is \" + str(time_diff) + \" times faster than pred!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
