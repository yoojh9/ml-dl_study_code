{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from IPython.display import Image\n",
    "\n",
    "tf.random.set_seed(678)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다층퍼셉트론 구조\n",
    "텐서플로우로 아래의 다층퍼셉트론을 구현해보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\" width=\"500\" height=\"250\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/dropout.png\", width=500, height=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data has 60000 samples\n",
      "every train data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"train data has \" + str(x_train.shape[0]) + \" samples\")\n",
    "print(\"every train data is \" + str(x_train.shape[1]) + \" * \" + str(x_train.shape[2])+ \" image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 흑백 이미지로 0에 가까울수록 흰색, 255에 가까울수록 검은색 픽셀이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드를 실행하여 각 데이터에 해당하는 레이블이 0부터 9까지의 숫자임을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data has 10000 samples\n",
      "every test data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
    "print(\"every test data is \" + str(x_test.shape[1]) \n",
    "      + \" * \" + str(x_test.shape[2]) + \" image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 정규화\n",
    "데이터 정규화는 보통 학습 시간을 단축하고, 더 나은 성능을 구하도록 도와준다.  \n",
    "MNIST 데이터의 모든 값은 0부터 255 범위 안에 있으므로 255로 나눔으로써 모든 값을 0과 1사이의 값으로 정규화한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 다층퍼셉트론 구현하기\n",
    "\n",
    "다층 퍼셉트론의 입력 레이어에 데이터를 넣기 위해 2d tensor(28,28)인 데이터를 1d tensor(28*28, 1)의 형태러ㅗ 바꾼다.  \n",
    "이는 행렬 형태의 데이터를 배열 형태의 데이터로 변경한다는 의미와 같다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/reshape_mnist.png\" width=\"300\" height=\"150\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/reshape_mnist.png\", width=300, height=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),   # 데이터 차원 변경\n",
    "    Dense(256, activation='relu'),  # 첫번째 히든 레이더(h1)\n",
    "    Dense(128, activation='relu'),  # 두번째 히든 레이어(h2)\n",
    "    Dropout(0.1),  # 두번째 히든 레이어(h2)에 드롭아웃(10%) 적용\n",
    "    Dense(10),     # 세번째 히든 레이어 (logit)\n",
    "    Activation('softmax')  # softmax layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 235,146\n",
      "Trainable params: 235,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 레이어에 784개의 입력을 받는 256개의 노드가 존재하고, 노드마다 편향값이 하나씩 존재하므로  \n",
    "784 * 256 + 256 = 200960의 파라미터가 존재한다.  \n",
    "flatten과 softmax는 노드가 없으므로 파라미터가 존재하지 않는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sparse_categorical_crossentropy:\n",
    "레이블을 원 핫 인코딩으로 자동으로 변경하여 크로스 엔트로피 측정합니다.\n",
    "\"\"\"\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 조기종료(Early Stopping)\n",
    "매 주기(Epoch)마다 검증 데이터로 검증 정확도를 측정한다.  \n",
    "검증 정확도가 5번 연속으로 개선되지 않을 시, 조기 종료를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=False),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 1.1574 - accuracy: 0.6674 - val_loss: 0.2151 - val_accuracy: 0.9403\n",
      "Epoch 2/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.2617 - accuracy: 0.9243 - val_loss: 0.1459 - val_accuracy: 0.9638\n",
      "Epoch 3/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1792 - accuracy: 0.9488 - val_loss: 0.1238 - val_accuracy: 0.9665\n",
      "Epoch 4/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1352 - accuracy: 0.9605 - val_loss: 0.1038 - val_accuracy: 0.9688\n",
      "Epoch 5/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.1129 - accuracy: 0.9680 - val_loss: 0.0910 - val_accuracy: 0.9730\n",
      "Epoch 6/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0950 - accuracy: 0.9718 - val_loss: 0.0867 - val_accuracy: 0.9742\n",
      "Epoch 7/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0756 - accuracy: 0.9790 - val_loss: 0.0807 - val_accuracy: 0.9758\n",
      "Epoch 8/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9813 - val_loss: 0.0766 - val_accuracy: 0.9785\n",
      "Epoch 9/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0564 - accuracy: 0.9838 - val_loss: 0.0763 - val_accuracy: 0.9768\n",
      "Epoch 10/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0455 - accuracy: 0.9869 - val_loss: 0.0721 - val_accuracy: 0.9793\n",
      "Epoch 11/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0416 - accuracy: 0.9885 - val_loss: 0.0731 - val_accuracy: 0.9797\n",
      "Epoch 12/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 0.0729 - val_accuracy: 0.9790\n",
      "Epoch 13/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.0698 - val_accuracy: 0.9810\n",
      "Epoch 14/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.0666 - val_accuracy: 0.9815\n",
      "Epoch 15/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0237 - accuracy: 0.9937 - val_loss: 0.0715 - val_accuracy: 0.9807\n",
      "Epoch 16/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.0662 - val_accuracy: 0.9817\n",
      "Epoch 17/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0188 - accuracy: 0.9949 - val_loss: 0.0679 - val_accuracy: 0.9810\n",
      "Epoch 18/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 0.0716 - val_accuracy: 0.9805\n",
      "Epoch 19/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 0.0681 - val_accuracy: 0.9808\n",
      "Epoch 20/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0705 - val_accuracy: 0.9810\n",
      "Epoch 21/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 0.0698 - val_accuracy: 0.9820\n",
      "Epoch 22/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 0.9977 - val_loss: 0.0658 - val_accuracy: 0.9837\n",
      "Epoch 23/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 0.9984 - val_loss: 0.0643 - val_accuracy: 0.9832\n",
      "Epoch 24/300\n",
      "54/54 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9983 - val_loss: 0.0716 - val_accuracy: 0.9828\n",
      "Epoch 25/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0696 - val_accuracy: 0.9820\n",
      "Epoch 26/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 0.0725 - val_accuracy: 0.9828\n",
      "Epoch 27/300\n",
      "54/54 [==============================] - 0s 8ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0727 - val_accuracy: 0.9833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd68cdba390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=300, batch_size=1000, validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test, y_test, verbose =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss, test acc :  [0.0741107165813446, 0.9797999858856201]\n"
     ]
    }
   ],
   "source": [
    "print('test loss, test acc : ', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
